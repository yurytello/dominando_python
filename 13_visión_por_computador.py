# -*- coding: utf-8 -*-
"""13 Visión por Computador.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AT10qLYBffqKOO0O5oxvx4Zxr8DawDI3

## Transformers

Transformers proporciona APIs para descargar y entrenar fácilmente modelos preentrenados de última generación
"""

from transformers import pipeline

# Cargamos el modelo CV pre-entrenado
classifier = pipeline(task="image-classification")

# Realizamos las predicciones
preds = classifier(
    "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
)
print(*preds, sep="\n")

"""## Identificación de Números Manuscritos

### Solución con Redes Neuronales Convolucionales CNNs
"""

import numpy as np
import keras
from keras.layers import Dense,Flatten, Dropout,Conv2D,MaxPooling2D,Activation
from keras.models import Sequential
from keras.datasets import mnist
import matplotlib.pyplot as plt

(x_train, y_train), (x_test, y_test) = mnist.load_data()

x_train = x_train.reshape(60000, 28, 28, 1).astype('float32')
x_test  = x_test.reshape(10000, 28, 28, 1).astype('float32')

x_train /= 255
x_test /= 255

n_classes = 10 #because we have 10 output

y_train = keras.utils.to_categorical(y_train, n_classes)
y_test = keras.utils.to_categorical(y_test, n_classes)

model = Sequential()
model.add(keras.Input(shape=(28, 28, 1)),)
model.add(Conv2D(32, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(10, activation='softmax'))

model.compile(loss='categorical_crossentropy', optimizer='RMSprop'  ,metrics=['accuracy'])

model.summary()

history = model.fit(x_train, y_train, epochs=5, batch_size=128 ,validation_data=(x_test, y_test))

# Evaluar el modelo en el conjunto de prueba
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)

print(f"\nPrecisión en el conjunto de prueba: {test_acc:.4f}")

# Graficar la precisión y pérdida del entrenamiento
plt.figure(figsize=(12, 4))

# Precisión
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Precisión de entrenamiento')
plt.plot(history.history['val_accuracy'], label='Precisión de validación')
plt.title('Precisión durante el entrenamiento')
plt.xlabel('Épocas')
plt.ylabel('Precisión')
plt.legend()

# Pérdida
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Pérdida de entrenamiento')
plt.plot(history.history['val_loss'], label='Pérdida de validación')
plt.title('Pérdida durante el entrenamiento')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.legend()

plt.show()

"""### Solución con solamente Redes Neuronales Profundas DL"""

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras import layers, models
from keras.datasets import mnist

# Cargar el dataset MNIST
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalizar las imágenes (valores entre 0 y 1)
x_train = x_train / 255.0
x_test = x_test / 255.0

# Mostrar algunas imágenes del dataset
plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.imshow(x_train[i], cmap="gray")
    plt.title(f"Etiqueta: {y_train[i]}")
    plt.axis("off")
plt.show()

# Crear el modelo
model = models.Sequential()

# Aplanar la imagen 28x28 en un vector de 784
model.add(layers.Flatten(input_shape=(28, 28)))

# Añadir capas ocultas densamente conectadas
model.add(layers.Dense(128, activation='relu'))  # Capa oculta de 128 neuronas
model.add(layers.Dense(64, activation='relu'))   # Capa oculta de 64 neuronas

# Capa de salida con 10 neuronas (una para cada clase)
model.add(layers.Dense(10, activation='softmax'))

# Compilar el modelo
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Resumen del modelo
model.summary()

# Entrenar el modelo
history = model.fit(x_train, y_train, epochs=5, batch_size=128 ,validation_data=(x_test, y_test))

# Evaluar el modelo en el conjunto de prueba
test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)

print(f"\nPrecisión en el conjunto de prueba: {test_acc:.4f}")

# Graficar la precisión y pérdida del entrenamiento
plt.figure(figsize=(12, 4))

# Precisión
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Precisión de entrenamiento')
plt.plot(history.history['val_accuracy'], label='Precisión de validación')
plt.title('Precisión durante el entrenamiento')
plt.xlabel('Épocas')
plt.ylabel('Precisión')
plt.legend()

# Pérdida
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Pérdida de entrenamiento')
plt.plot(history.history['val_loss'], label='Pérdida de validación')
plt.title('Pérdida durante el entrenamiento')
plt.xlabel('Épocas')
plt.ylabel('Pérdida')
plt.legend()

plt.show()